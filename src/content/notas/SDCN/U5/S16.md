# Latencia versus throughtput

Hay muchas métricas diferentes que se pueden usar para medir la velocidad de las transferencias de datos de una red. Ser capaz de determinar la velocidad de un servicio proporciona una métrica para medir el rendimiento de la red. La latencia y el rendimiento son una de la forma más comunes en que se miden las redes. Medir el nivel de rendimiento o latencia pueden ayudar a identificar problemas de rendimiento de una red. En el diseño de los SD tenemos una compensación de diseño entre la latencia y el rendimiento.

## Latencia
Mide el tiempo (máximo, percentil o promedio) que nos toma:
- Completar un trabajo
- Recibir la respuesta a una invocación remota
- Transmitir el primer byte de un conjunto de datos

## Throughput
Mide:
- Número de trabajos completados por segundo
- Cantidad de invocaciones remotas atendidas por unidad de tiempo
- Transacciones por segundo (tps)
- Cantidad de datos transmitidos por unidad de tiempo

## Latencia vs Throughput
- En un SD, se debe analizar cuál de estos dos se debe optimizar.
- Los dos tienen una relación de causa y efecto

> Mientras más tardaran los datos en llegar a su destino, mayor será la latencia.

> Mientras más ancho de banda tenga, los paquetes llegarán más rápido a su destino, incluso si tiene baja latencia.

- Si no estoy seguro, se optimiza la latencia.

HDFS optimiza el throughput y no la latencia: puede transmitir grandes cantidades de manera rápida, pero el primer registro de estos datos no llega muy rápido debido a que hay un overhead asociado con contactar el servidor de metadatos (Namenode).

## Ejercicios

¿Qué se debe optimizar en los siguientes casos?

- Sistemas de procesamiento distribuidos por lotes
Puede ser útil para reducir el impacto de la latencia para mejorar el rendimiento, cuando está alcanzando el límite de rendimiento que puede logar. El procesamiento distribuido por lotes puede mejorar la sobrecarga y proporcionar rendimiento más altos y latencias más bajas.

- Sistemas de consultas ad-hoc distribuidas
Una consulta ad-hoc no reside en el sistema por mucho tiempo, y el usuario la crea automáticamente a pedido. Este tipo de consulta desafía la velocidad de procesamiento y la memoria de tiempo de ejecución del sistema.
Por lo que la latencia podría ser alta y se recomienda optimizarla.

- Base de datos clave-valor
Primordial el acceso a los datos de baja latencia y de alto rendimiento.

¿Cuántos nos tardaríamos en enviar 1 PB de una empresa a otra si la conexión a internet es de 20 Gbs?

$20 \ Gbs \to 0.009 \ PBh$
$\frac {1 PB}{0.009 \ PBh} = 111.1111 \ horas = 4.6 \ días$


## Sneakernet

Mejora la latencia de envío. Es un termino informal usado para la transferencia de información electrónica por medios desprendibles físicamente a partir de un ordenador personal a otro. Esto sustituye la traslación de la información sobre una red de computadores debido a las limitaciones del ancho demanda, o por motivas de seguridad, o simplemente por la carencia de una red.

Ejemplo real:

> Equipo que genero la primera imagen de un agujero negro. Enviaron los datos en discos duros por avión. No hay internet que pueda competir con petabytes de datos con un avión

> Dispositivos AWS Snowball, es una solución de transporte de datos a escala de petabyes. Que utiliza dispositivos seguros para transmitir grandes volúmenes de datos desde y hacia la nube de AWS. Usar Snowball permite resolver los desafíos propios de la transferencia de  datos a gran escalas. Incluye los altos costo de red, los tiempos prolongados de transferencia y los riesgos para la seguridad.

>  AWS Snowmobile, un servicio de transferencia de datos a escala de hexabites para la transferencia de volúmenes de datos extra grandes a AWS. Puede transferir hasta 100 petabytes. 

## Desafío Latencia Consistente

- Es difícil encontrar escenario ideales
- Picos (burst) de tráficos y fallas pueden ocurrir

Una solución podría ser la estrategia de contra presión (back pressure), es cuando la tasa de producción excede la tasa de consumo. Y la cola alcanza la capacidad.

Una opción es que el sistema se bloquee hasta que haya un lugar disponible en la cola. Para implementar esta política, todas las colas deben estar limitadas a un tamaño que evite el uso excesivo de recurso. Y la producción de colas debe bloquearse cuando estén llenas.


## Conclusión
En esta sección definimos la Latencia y Throughput o rendimiento. Discutimos la relación de causa y efecto entre ellos y analizamos cuál de los dos se debe optimizar. También hablamos sobre ejemplos reales en donde el Sneakernet se ha usado par optimizar la latencia en sistemas.